version: '3.8'

services:
  # Ollama LLM backend
  ollama:
    image: ollama/ollama
    container_name: ollama
    volumes:
      - ollama_data:/root/.ollama  # persist Ollama models/config
    restart: unless-stopped

  # Translator microservice (Flask)
  translator:
    build:
      context: ../llm-experiment-microservice-jack
      dockerfile: Dockerfile
    command: flask run --host=0.0.0.0
    depends_on:
      - ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - FLASK_APP=app.py
      - FLASK_ENV=development
    ports:
      - "5000:5000"
    working_dir: /app
    restart: unless-stopped

  # NodeBB Forum
  nodebb:
    user: "0"  # allow root for initial file permissions
    build: .
    restart: unless-stopped
    ports:
      - "4567:4567"  # main web forum
    volumes:
      - nodebb-build:/usr/src/app/build
      - nodebb-uploads:/usr/src/app/public/uploads
      - nodebb-config:/opt/config
      - ./install/docker/setup.json:/usr/src/app/setup.json
    environment:
      MAILGUN_API_KEY: ${MAILGUN_API_KEY}
      MAILGUN_DOMAIN: ${MAILGUN_DOMAIN}
      TRANSLATOR_API_URL: http://translator:5000  # <-- new env var (NodeBB can call translator)
    depends_on:
      - redis
      - translator

  # Redis cache
  redis:
    image: redis:8.0.1-alpine
    restart: unless-stopped
    command: ["redis-server", "--appendonly", "yes", "--loglevel", "warning"]
    volumes:
      - redis-data:/data

# ---------- Named Volumes ----------

volumes:
  ollama_data:

  redis-data:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: ./.docker/database/redis

  nodebb-build:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: ./.docker/build

  nodebb-uploads:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: ./.docker/public/uploads

  nodebb-config:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: ./.docker/config
